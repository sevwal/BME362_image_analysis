{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sevwal/BME362_image_analysis/blob/main/Image_Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "8po-oTzUTukf"
      },
      "cell_type": "markdown",
      "source": [
        "# **BME362: Image Processing**\n",
        "We will be running a relatively simple image processing pipeline. As I'm not aware of your skill levels in coding, this script is meant to be fancy enough to excite you but simple enough to follow through easily. Of course, I will be here to help you throughout the course should you have any questions!\n",
        "\n",
        "We will make use of the open source functionalities of Python. One powerful aspect of Python is the easy install of the abundant packages and dependencies that suit your needs. And of course: the large community that codes all of this and makes it accessible to you for free :D We will make use of:\n",
        "\n",
        "*   `OpenCV` (Open Source Computer Vision Library, https://github.com/opencv/opencv/wiki) is a tool for computer vision and machine learning. It provides us with some powerful algorithms to process our images.\n",
        "*   `Cellpose` (https://github.com/MouseLand/cellpose) is a tool for image segmentation of cells and nuclei. It provides us with the ability to train a neural network for image segmentation. Don't worry, we won't go that deep in this short training and will make use of the pre-trained models cellpose provides to us.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Remarks: This script was inspired by the documentation on [Cellpose](https://github.com/MouseLand/cellpose) and their example notebooks, workflows developed by Joel Lüthi ([Twitter](https://twitter.com/joel_luethi), [Github](https://github.com/jluethi)), as well as the notebook [Running cellpose 2.0 in colab with a GPU](https://colab.research.google.com/github/MouseLand/cellpose/blob/main/notebooks/run_cellpose_2.ipynb#scrollTo=Q7c7V4yEqDc_).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preliminaries**"
      ],
      "metadata": {
        "id": "TVzWcAf1QzcM"
      }
    },
    {
      "metadata": {
        "id": "YcL2ZCWyDF2U"
      },
      "cell_type": "markdown",
      "source": [
        "## **Step 1:** Get your files in here\n",
        "Before we get started, you should select a couple of nice images that you want to take a look at. We want to make our files accessible to Google Colab. There's two ways of doing this:\n",
        "\n",
        "1.   Connect your Google Drive, if you have one (Recommended)\n",
        "2.   Upload them to Colab (Files will disappear if session disconnects)\n",
        "\n",
        "Depending on which option you choose, uncomment the code below and make sure your images are uploaded."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Google Drive\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "rB-KERJsXSKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Local upload\n",
        "#from google.colab import files\n",
        "#uploaded = files.upload()"
      ],
      "metadata": {
        "id": "LKC86ek-XZWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 2:** Setup Cellpose and Import Libraries\n",
        "The code below just installs OpenCV and the GPU version of Cellpose. \n",
        "\n",
        "After installation, you will get an error that your runtime has crashed. **Do not worry this is part of the plan**"
      ],
      "metadata": {
        "id": "QK0DYtGqX_Cj"
      }
    },
    {
      "metadata": {
        "id": "ieiTHw1HDwRM",
        "outputId": "e6c2f47c-833d-4935-da05-bb92840e653a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "#!pip install git+https://www.github.com/mouseland/cellpose.git #to install development version\n",
        "!pip install cellpose\n",
        "!pip install torch torchvision torchaudio\n",
        "\n",
        "#Fix opencv error: ImportError: cannot import name '_registerMatType' from 'cv2.cv2'\n",
        "!pip install \"opencv-python-headless<4.3\"\n",
        "exit(0) #Restart Runtime to use newly installed numpy"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting cellpose\n",
            "  Downloading cellpose-2.1.0-py3-none-any.whl (169 kB)\n",
            "\u001b[K     |████████████████████████████████| 169 kB 23.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tifffile in /usr/local/lib/python3.7/dist-packages (from cellpose) (2021.11.2)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.7/dist-packages (from cellpose) (1.12.1+cu113)\n",
            "Collecting fastremap\n",
            "  Downloading fastremap-1.13.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 40.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python-headless in /usr/local/lib/python3.7/dist-packages (from cellpose) (4.6.0.66)\n",
            "Requirement already satisfied: llvmlite in /usr/local/lib/python3.7/dist-packages (from cellpose) (0.39.1)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from cellpose) (1.21.6)\n",
            "Collecting imagecodecs\n",
            "  Downloading imagecodecs-2021.11.20-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 31.0 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from cellpose) (4.64.1)\n",
            "Requirement already satisfied: numba>=0.53.0 in /usr/local/lib/python3.7/dist-packages (from cellpose) (0.56.2)\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.7/dist-packages (from cellpose) (5.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from cellpose) (1.7.3)\n",
            "Requirement already satisfied: setuptools<60 in /usr/local/lib/python3.7/dist-packages (from numba>=0.53.0->cellpose) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from numba>=0.53.0->cellpose) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6->cellpose) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba>=0.53.0->cellpose) (3.8.1)\n",
            "Installing collected packages: imagecodecs, fastremap, cellpose\n",
            "Successfully installed cellpose-2.1.0 fastremap-1.13.3 imagecodecs-2021.11.20\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "-jQf-JqMCRgn"
      },
      "cell_type": "markdown",
      "source": [
        "As with all Python packages, installing is not enough. We need to import (and thus load) them to make them available for us to use."
      ]
    },
    {
      "metadata": {
        "id": "ZEZu6Q22Bi0e"
      },
      "cell_type": "code",
      "source": [
        "#disabled installation and import of mxnet as pytorch is the default neural net\n",
        "import numpy as np\n",
        "import time, os, sys, random\n",
        "from urllib.parse import urlparse\n",
        "import skimage.io\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "%matplotlib inline\n",
        "mpl.rcParams['figure.dpi'] = 300\n",
        "\n",
        "from urllib.parse import urlparse\n",
        "import shutil"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 3:** Check GPU access and download Cellpose Models\n",
        "Next up, we will download the pre-trained models from cellpose. Cellpose comes with the following pre-trained models:\n",
        "\n",
        "*   Cytoplasm (`cyto`)\n",
        "*   Cytoplasm2 (`cyto2`)\n",
        "*   Cytoplasm2_Omnipose (`cyto2_omni`)\n",
        "*   Bacteroa_Omnipose (`bact_omni`)\n",
        "*   Nuclei (`nuclei`)\n",
        "\n",
        "Cytoplasm and Cytoplasm2 are two differently trained cytoplasm models (remember that these models are neural networks!). We can use either one but depending on your cells one may perform better than the other. The model for nuclei is pretty solid, as nuclei shapes are very similar across cell types.\n",
        "\n",
        "Omnipose uses a different algorithm to provide robust segmentation of elongated cell shapes (such as certain bacteria and other cells). We will not need this here.\n"
      ],
      "metadata": {
        "id": "svwKLY8CgRJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Downloading Models\")\n",
        "from cellpose import models,core\n",
        "#https://stackoverflow.com/questions/8924173/how-do-i-print-bold-text-in-python\n",
        "BOLD = '\\033[1m'\n",
        "UNDERLINE = '\\033[4m'\n",
        "END = '\\033[0m'\n",
        "\n",
        "#Check if colab notebook instance has GPU access\n",
        "if core.use_gpu()==False: \n",
        "  #Warnings from the ZeroCost StarDist notebook\n",
        "  print(BOLD+UNDERLINE+'You do not have GPU access.'+END)\n",
        "  print('Did you change your runtime ?') \n",
        "  print('If the runtime setting is correct then Google did not allocate a GPU for your session')\n",
        "  print('Expect slow performance. To access GPU try reconnecting later')\n",
        "  use_GPU=False\n",
        "else:\n",
        "  print(BOLD+UNDERLINE+\"You have access to the GPU.\"+END+\"\\nDetails are:\")\n",
        "  print(\"*************************************************\")\n",
        "  !nvidia-smi\n",
        "  use_GPU=True\n",
        "\n",
        "print(\"*************************************************\")\n",
        "print(\"Libraries imported and configured\")"
      ],
      "metadata": {
        "id": "enpkbv3IgBVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 4:** Prepare your paths\n",
        "In Step 1 you prepared your images. Now's the time to use them: enter the full path as `Input_Directory` below.\n",
        "\n",
        "Also make sure to provide your image format as `image_format`. In general, image analysis is always only recommended for ***lossless image formats*** such as ***TIF*** or ***PNG***. Jpeg is considered a lossy format, as it deletes part of the information in your images to compress them more. For more information, Wikipedia's page on image compression is pretty good (https://en.wikipedia.org/wiki/Image_compression).\n",
        "\n",
        "As you should have seen, we will always use naming conventions to orient ourselves in the gazillion of images we take. The simplest solution now is to just throw everything into one folder, read that into `Python` as a path, and then access the files through loops and changing pathnames. Like this, you never have to specify individual files, which is helpful if you're dealing with >10k images."
      ],
      "metadata": {
        "id": "oseJsfZZjYDy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify input directory\n",
        "Input_Directory = \"/content/gdrive/MyDrive/BME362_sample_data\"\n",
        "input_dir = os.path.join(Input_Directory, \"\") #adds separator to the end regardless if path has it or not\n",
        "\n",
        "#Specify img format\n",
        "image_format = \"png\"\n",
        "\n",
        "#Create a new folder where we will store our mask\n",
        "save_dir = input_dir+\"Masks/\"\n",
        "if not os.path.exists(save_dir):\n",
        "  os.makedirs(save_dir)\n",
        "else:\n",
        "  #If there already is a folder, delete it\n",
        "  print(\"Existing Mask Directory found. Deleting it.\")\n",
        "  shutil.rmtree(save_dir)\n",
        "\n",
        "# r=root, d=directories, f = files\n",
        "files=[]\n",
        "\n",
        "for r, d, f in os.walk(input_dir):\n",
        "    for fil in f:\n",
        "      if (image_format):\n",
        "        if fil.endswith(image_format):\n",
        "          files.append(os.path.join(r, fil))\n",
        "      else:\n",
        "        files.append(os.path.join(r, fil))\n",
        "    break #only read the root directory; can change this to include levels\n",
        "if(len(files)==0):\n",
        "  print(\"Number of images loaded: %d.\" %(len(files)))\n",
        "  print(\"Cannot read image files. Check if folder has images\")\n",
        "else:\n",
        "  print(\"Number of images loaded: %d.\" %(len(files)))"
      ],
      "metadata": {
        "id": "oqIs7JxBn5f4",
        "outputId": "c02db18b-baba-496d-8a0c-d8dbb48370ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/BME362_sample_data/AssayPlate_Greiner_655090_D02_T0001F001L01A01Z01C01.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **On to our images!**"
      ],
      "metadata": {
        "id": "E0697lNyoRoJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 5**: Read and Load all the images\n",
        "In this step we will check our images. As always, we would like to check if everything is set up correctly before blindly heading into later steps. So this will allow us to see if we are working with the correct images and double check the channel names for later.\n",
        "\n",
        "Note that *we do not need to do anything here*, we can simply run this code as we have specified all necessary variables already. ٩(◕‿◕)۶"
      ],
      "metadata": {
        "id": "9wL3e4C0EI0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imgs=[] #store all images\n",
        "#Read images\n",
        "for f in files:\n",
        "  im=skimage.io.imread(f)\n",
        "  n_dim=len(im.shape) #shape of image\n",
        "  dim=im.shape #dimensions of image\n",
        "  channel=min(dim) #channel will be dimension with min value usually\n",
        "  channel_position=dim.index(channel)\n",
        "  #if no of dim is 3 and channel is first index, swap channel to last index\n",
        "  if n_dim==3 and channel_position==0: \n",
        "    #print(dim)\n",
        "    im=im.transpose(1,2,0)\n",
        "    dim=im.shape\n",
        "    #print(\"Shape changed\")\n",
        "  #print(dim)\n",
        "  imgs.append(im)\n",
        "\n",
        "nimg = len(imgs)\n",
        "print(\"No of images loaded are: \", nimg)\n",
        "\n",
        "print(\"Example Image:\")\n",
        "\n",
        "random_idx = random.choice(range(len(imgs)))\n",
        "x=imgs[random_idx]\n",
        "n_dim=len(x.shape)\n",
        "file_name=os.path.basename(files[random_idx])\n",
        "print(file_name+\" has \"+str(n_dim)+\" dimensions/s\")\n",
        "if n_dim==3:\n",
        "  channel_image=x.shape[2]\n",
        "  fig, axs = plt.subplots(1, channel_image,figsize=(12,5))\n",
        "  print(\"Image: %s\" %(file_name))\n",
        "  for channel in range(channel_image):\n",
        "      axs[channel].imshow(x[:,:,channel])\n",
        "      axs[channel].set_title('Channel '+str(channel+1),size=5)\n",
        "      axs[channel].axis('off')\n",
        "  fig.tight_layout()\n",
        "elif n_dim==2:\n",
        "  print(\"One Channel\")\n",
        "  plt.imshow(x)\n",
        "else:\n",
        "  print(\"Channel number invalid or dimensions wrong. Image shape is: \"+str(x.shape))"
      ],
      "metadata": {
        "id": "g0N5TCan8Ey8"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 6:** Specify parameters for the nuclear segmentation"
      ],
      "metadata": {
        "id": "ITklk6XboLDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_choice = \"Cytoplasm2\" #@param [\"Cytoplasm\",\"Cytoplasm2\", \"Cytoplasm2_Omnipose\", \"Bacteria_Omnipose\", \"Nuclei\"]\n",
        "\n",
        "print(\"Using model \",model_choice)\n",
        "\n",
        "Channel_for_segmentation=\"2\" #@param[0,1,2,3]\n",
        "segment_channel=int(Channel_for_segmentation)\n",
        "\n",
        "Use_nuclear_channel=True\n",
        "Nuclear_channel=\"1\"\n",
        "nuclear_channel=int(Nuclear_channel)\n",
        "\n",
        "diameter=0\n",
        "\n",
        "# define CHANNELS to run segementation on\n",
        "# grayscale=0, R=1, G=2, B=3\n",
        "# channels = [cytoplasm, nucleus]\n",
        "# if NUCLEUS channel does not exist, set the second channel to 0\n",
        "# channels = [0,0]\n",
        "# IF ALL YOUR IMAGES ARE THE SAME TYPE, you can give a list with 2 elements\n",
        "# channels = [0,0] # IF YOU HAVE GRAYSCALE\n",
        "# channels = [2,3] # IF YOU HAVE G=cytoplasm and B=nucleus\n",
        "# channels = [2,1] # IF YOU HAVE G=cytoplasm and R=nucleus\n",
        "\n",
        "model_type=\"nuclei\"\n",
        "\n",
        "# channels = [cytoplasm, nucleus]\n",
        "if model_choice not in \"Nucleus\":\n",
        "  if Use_nuclear_channel:\n",
        "    channels=[segment_channel,nuclear_channel]\n",
        "  else:\n",
        "    channels=[segment_channel,0]\n",
        "else: #nucleus\n",
        "  channels=[segment_channel,0]\n",
        "\n",
        "\n",
        "# DEFINE CELLPOSE MODEL\n",
        "# model_type='cyto' or model_type='nuclei'\n",
        "model = models.Cellpose(gpu=use_GPU, model_type=model_type)\n",
        "\n",
        "# define CHANNELS to run segementation on\n",
        "# grayscale=0, R=1, G=2, B=3\n",
        "# channels = [cytoplasm, nucleus]\n",
        "# if NUCLEUS channel does not exist, set the second channel to 0\n",
        "# channels = [0,0]\n",
        "# IF ALL YOUR IMAGES ARE THE SAME TYPE, you can give a list with 2 elements\n",
        "# channels = [0,0] # IF YOU HAVE GRAYSCALE\n",
        "# channels = [2,3] # IF YOU HAVE G=cytoplasm and B=nucleus\n",
        "# channels = [2,1] # IF YOU HAVE G=cytoplasm and R=nucleus\n",
        "\n",
        "# or if you have different types of channels in each image\n",
        "# channels = [[2,3], [0,0], [0,0]]\n",
        "\n",
        "# if diameter is set to None, the size of the cells is estimated on a per image basis\n",
        "# you can set the average cell `diameter` in pixels yourself (recommended) \n",
        "# diameter can be a list or a single number for all images\n",
        "if diameter is 0:\n",
        "  diameter = None\n",
        "  print(\"Diameter is set to None. The size of the cells will be estimated on a per image basis\")"
      ],
      "metadata": {
        "id": "fWzp5nZk9bYb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "5d8637f4-8786-46a2-aebf-fa155d61c235"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using model  Cytoplasm2\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-da363795433b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# DEFINE CELLPOSE MODEL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# model_type='cyto' or model_type='nuclei'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCellpose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_GPU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# define CHANNELS to run segementation on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'models' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "_jRARxh6RmXp"
      },
      "cell_type": "markdown",
      "source": [
        "## **Step 7:** Test the nuclear segmentation\n",
        "Next up, we want to check our images and have a look at what we have. For this,we will create a quick function that displays three of our images using `matplotlib.pyplot` (imported as `plt`)."
      ]
    },
    {
      "metadata": {
        "id": "MogmXqbeRhsg"
      },
      "cell_type": "code",
      "source": [
        "from skimage.util import img_as_ubyte\n",
        "\n",
        "Image_Number = 1 #indexing starts at zero\n",
        "#print(Image_Number)\n",
        "diameter = 400\n",
        "flow_threshold = 0.4\n",
        "\n",
        "Cell_Probability_Threshold=0\n",
        "cellprob_threshold=Cell_Probability_Threshold\n",
        "\n",
        "if diameter is 0:\n",
        "  diameter = None\n",
        "if Image_Number is -1:\n",
        "  Image_Number=0\n",
        "  #print(\"Image_Number is set to zero, opening first image.\")\n",
        "try:\n",
        "    image = imgs[Image_Number]\n",
        "except IndexError as i:\n",
        "   print(\"Image number does not exist\",i)\n",
        "   print(\"Actual no of images in folder: \",len(imgs))\n",
        "print(\"Image: %s\" %(os.path.splitext(os.path.basename(files[Image_Number]))[0]))\n",
        "img1=imgs[Image_Number]\n",
        "\n",
        "import cv2\n",
        "\n",
        "masks, flows, styles, diams = model.eval(img1, resample=True,\n",
        "                                         diameter=diameter, \n",
        "                                         flow_threshold=flow_threshold,\n",
        "                                         cellprob_threshold=cellprob_threshold, \n",
        "                                         channels=channels)\n",
        "\n",
        "\n",
        "\n",
        "# DISPLAY RESULTS\n",
        "from cellpose import plot\n",
        "maski = masks\n",
        "flowi = flows[0]\n",
        "\n",
        "#convert to 8-bit if not so it can display properly in the graph\n",
        "if img1.dtype!='uint8':\n",
        "  img1=img_as_ubyte(img1)\n",
        "\n",
        "fig = plt.figure(figsize=(24,8))\n",
        "plot.show_segmentation(fig, img1, maski, flowi, channels=channels)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 8:** Specify parameters for the cytoplasmic segmentation"
      ],
      "metadata": {
        "id": "IuF_kXKquX0K"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pLVIYTFlua-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 9:** Test the cytoplasmic segmentation"
      ],
      "metadata": {
        "id": "GZIpoxcwufxc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i3dLEw7QufRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 10:** Run cellpose, segment cells, and write output to folder"
      ],
      "metadata": {
        "id": "NZxSupzVu8ll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### **Step 8. Run Cellpose on folder of images**\n",
        "\n",
        "#@markdown ###Tick if you want to save the flow image/s: \n",
        "Save_Flow= False #@param {type:\"boolean\"}\n",
        "#@markdown ##### *Flow image will be resized when saved\n",
        "save_flow=Save_Flow\n",
        "\n",
        "print(\"Running segmentation on channel %s\" %(segment_channel))\n",
        "print(\"Using the model: \",model_choice)\n",
        "if diameter is None:\n",
        "  print(\"Diameter will be estimated from the image/s\")\n",
        "else:\n",
        "  print(f\"Cellpose will use a diameter of {diameter}\")\n",
        "\n",
        "print(f\"Using a flow threshold of: {flow_threshold} and a cell probability threshold of: {cellprob_threshold}\")\n",
        "\n",
        "#if too many images, it will lead to memory error. \n",
        "#will evaluate on a per image basis\n",
        "#masks, flows, styles, diams = model.eval(imgs, diameter=diameter, flow_threshold=flow_threshold,cellprob_threshold=cellprob_threshold, channels=channels)\n",
        "\n",
        "\n",
        "#save images in folder with the diameter value used in cellpose\n",
        "print(\"Segmentation Done. Saving Masks and flows now\")\n",
        "print(\"Save Directory is: \",save_dir)\n",
        "if (not os.path.exists(save_dir)):\n",
        "    os.mkdir(save_dir)\n",
        "\n",
        "if save_flow:\n",
        "  print(\"Saving Flow\")\n",
        "  flows_save_dir=save_dir+\"flows\"+os.sep\n",
        "  print(\"Save Directory for flows is: \",flows_save_dir)\n",
        "  if (not os.path.exists(flows_save_dir)):\n",
        "      os.mkdir(flows_save_dir)\n",
        "\n",
        "\n",
        "for img_idx, img in enumerate(imgs):\n",
        "    file_name=os.path.splitext(os.path.basename(files[img_idx]))[0]\n",
        "    print(\"\\nSegmenting: \",file_name)\n",
        "    mask, flow, style, diam = model.eval(img, diameter=diameter, flow_threshold=flow_threshold,cellprob_threshold=cellprob_threshold, channels=channels)\n",
        "    #save images in folder with the diameter value used in cellpose\n",
        "    print(\"Segmentation complete . Saving Masks and flows\")\n",
        "    #Output name for masks\n",
        "    mask_output_name=save_dir+\"MASK_\"+file_name+\".tif\"\n",
        "    #Save mask as 16-bit in case this has to be used for detecting than 255 objects\n",
        "    mask=mask.astype(np.uint16)\n",
        "    #Save flow as 8-bit\n",
        "    skimage.io.imsave(mask_output_name,mask, check_contrast=False)\n",
        "    if save_flow:\n",
        "      #Output name for flows\n",
        "      flow_output_name=flows_save_dir+\"FLOWS_\"+file_name+\".tif\"\n",
        "      #Save as 8-bit\n",
        "      flow_image=flow[0].astype(np.uint8)\n",
        "      skimage.io.imsave(flow_output_name,flow_image, check_contrast=False)\n",
        "\n",
        "#Save parameters used in Cellpose\n",
        "parameters_file=save_dir+\"Cellpose_parameters_used.txt\" \n",
        "outFile=open(parameters_file, \"w\") \n",
        "outFile.write(\"CELLPOSE PARAMETERS\\n\") \n",
        "outFile.write(\"Model: \"+model_choice+\"\\n\") \n",
        "if diameter == 0:\n",
        "  diameter = \"Automatically estimated by cellpose\"\n",
        "outFile.write(\"Omni Flag: \"+str(omni)+\"\\n\") \n",
        "outFile.write(\"Diameter: \"+str(diameter)+\"\\n\") \n",
        "outFile.write(\"Flow Threshold: \"+str(flow_threshold)+\"\\n\") \n",
        "outFile.write(\"Cell probability Threshold: \"+str(cellprob_threshold)+\"\\n\") \n",
        "outFile.close() \n",
        "print(\"\\nSegmentation complete and files saved\")"
      ],
      "metadata": {
        "id": "jP89lzwwu8Q8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}